{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторна робота 3 - Логістична регресія."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У цій роботі Ви побудуєте логістичну регресію для класифікації зображень рукописних символів за датасетом MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У файлі **mnist.npz** міститься датасет MNIST. Завантажимо його та візуалізуємо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28)\n",
      "x_test shape: (10000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with np.load('mnist.npz') as npz:\n",
    "    x_train, y_train, x_test, y_test = [npz[k] for k in ['x_train', 'y_train', 'x_test', 'y_test']]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 4),  ncols=5)\n",
    "for a in ax:\n",
    "    i = np.random.randint(x_train.shape[0])\n",
    "    a.matshow(x_train[i], cmap='gray')\n",
    "    a.set_title(f'Label: {y_train[i]}')\n",
    "    a.axis('off')\n",
    "    \n",
    "print(f'x_train shape: {x_train.shape}')\n",
    "print(f'x_test shape: {x_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Як можна помітити, дані в датасеті MNIST подано у вигляді **тензора** рангу 3 (тензор рангу 1 це вектор, 2 - матриця), або, по-простому, у вигляді тривимірної таблиці. Ми поки що не знаємо алгоритмів, які здатні приймати на вхід такі дані, тому перетворимо весь наш датасет так, щоб кожна картинка була представлена у вигляді вектора довжини $28\\cdot28=784$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape after reshape: (60000, 784)\n",
      "x_test shape after reshape: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(-1, 28 * 28)\n",
    "x_test = x_test.reshape(-1, 28 * 28)\n",
    "\n",
    "print(f'x_train shape after reshape: {x_train.shape}')\n",
    "print(f'x_test shape after reshape: {x_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким чином ми отримали датасет, у якому 784 ознаки. Кожна ознака - інтенсивність певного пікселя картинки.\n",
    "\n",
    "Для більш ефективного зберігання, інтенсивності пікселів представлені цілочисельним типом uint8, який, на жаль, не підходить для виконання логістичної регресії (оскільки він цілочисельний). Перетворюємо дані в float32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реалізуйте методи з позначкою `#TODO` класу LogisticRegression:\n",
    "\n",
    "Метод `preprocess` повинен додавати колонку з одиниць у матрицю $X$. Опціонально - додайте поліноміальні або будь-які інші нелінійні ознаки.\n",
    "\n",
    "Метод `onehot` повинен виконувати onehot-перетворення:\n",
    "$$\n",
    " \\begin{array}{l}\n",
    "onehot:\\ \\mathbb{R}\\rightarrow \\mathbb{R}^{c}\\\\\n",
    "\\overline{onehot(y_{i} )}_{j} =\\begin{cases}\n",
    "1, & j=y_{i}\\\\\n",
    "0, & j\\neq y_{i}\n",
    "\\end{cases}\n",
    "\\end{array}\n",
    "$$\n",
    "де $c$ - кількість класів.\n",
    "\n",
    "Метод `h` - гіпотеза:\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "h( X) =\\sigma ( X\\theta )\\\\\n",
    "\\sigma ( x) =\\frac{1}{1+e^{-x}}\n",
    "\\end{array}\n",
    "$$\n",
    "Метод `J` повинен обчислювати оціночну функцію логістичної регресії:\n",
    "$$\n",
    "J( \\theta ) =\\frac{1}{m}\\sum ^{m}_{i=1}\\sum ^{c}_{j=1}( -y_{i,j} \\cdot \\log( h( x_{i})_j) \\ -\\ ( 1\\ -\\ y_{i,j}) \\cdot \\log( 1\\ -\\ h( x_{i})_j) +\\alpha _{1}\\sum ^{N}_{i=1}\\sum ^{c}_{j=1} |\\hat{\\theta }_{i,j} |+\\alpha _{2}\\sum ^{N}_{i=1}\\sum ^{c}_{j=1}\\hat{\\theta }^{2}_{i,j}\n",
    "$$\n",
    "Метод `grad` має обчислювати градієнт $\\frac{\\partial J}{\\partial \\theta }$:\n",
    "$$\n",
    "{\\displaystyle \\frac{\\partial J}{\\partial \\theta }} =-{\\displaystyle \\frac{1}{m}} X^{T} (Y-h(X) )+\\begin{bmatrix}\n",
    "0 &  &  & \\\\\n",
    " & 1 &  & \\\\\n",
    " &  & \\ddots  & \\\\\n",
    " &  &  & 1\n",
    "\\end{bmatrix} \\times ( \\alpha _{1} sign(\\theta )+2\\alpha _{2} \\theta )\n",
    "$$\n",
    "Метод `moments` має повертати вектор-рядки $\\mu,\\sigma$ для середнього і стандартного відхилення кожної колонки. Пам'ятайте, що колонку з одиницями не потрібно нормалізувати, тож відповідні середнє і стандартне відхилення для неї вкажіть рівними 0 і 1 відповідно. Можна використовувати функції \n",
    "[np.mean](https://numpy.org/doc/stable/reference/generated/numpy.mean.html) і [np.std](https://numpy.org/doc/stable/reference/generated/numpy.std.html).\n",
    "\n",
    "Метод `normalize` має виконувати нормалізацію $X$ на основі статистик $\\mu,\\sigma$, що повернув метод **moments**. Для того щоб уникнути ділення на 0, можете до $\\sigma$ додати маленьку величину, наприклад $10^{-8}$.\n",
    "\n",
    "Метод `get_batch` має повертати матриці $X_b, Y_b$ з довільно обраних $b$ елементів вибірки ($b$ у коді - `self.batch_size`).\n",
    "\n",
    "Метод `fit` виконує оптимізацію $J(\\theta)$. Для кращої збіжності реалізуйте алгоритм оптимізації **Momentum**:\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "v_t = \\gamma v_{t-1} + \\alpha\\nabla J(\\theta_{t-1})\\\\\n",
    "\\theta_t = \\theta_{t-1} - v_t\n",
    "\\end{array}\n",
    "$$\n",
    "де $\\gamma$ встановіть рівним $0.9$ (можете поекспериментувати з іншими величинами), $v_1=[0]_{N,c}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(\n",
    "        self,\n",
    "        alpha1,\n",
    "        alpha2,\n",
    "        learning_rate,\n",
    "        batch_size,\n",
    "        train_steps\n",
    "    ):\n",
    "        self.alpha1 = alpha1\n",
    "        self.alpha2 = alpha2\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.train_steps = train_steps\n",
    "    \n",
    "    def preprocess(self, x):\n",
    "        x = np.hstack((np.ones((x.shape[0], 1)), x))\n",
    "\n",
    "        poly_features = x[:, 1:] ** 2\n",
    "        x = np.hstack((x, poly_features))\n",
    "        return x\n",
    "    \n",
    "    def onehot(self, y):\n",
    "        y_onehot = np.zeros((y.size, y.max() + 1), dtype=np.float32)\n",
    "        y_onehot[np.arange(y.size), y] = 1\n",
    "        return y_onehot\n",
    "    \n",
    "    def normalize(self, x):\n",
    "        # TODO\n",
    "        return\n",
    "\n",
    "    def moments(self, x):\n",
    "        mu = np.mean(x, axis=0)\n",
    "        sigma = np.std(x, axis=0)\n",
    "\n",
    "        mu[0] = 0\n",
    "        sigma[0] = 1\n",
    "\n",
    "        return mu, sigma\n",
    "    \n",
    "    def J(self, x, y, theta):\n",
    "        m = x.shape[0]\n",
    "        h_x = self.h(x, theta)\n",
    "\n",
    "        cost = 1 / m * np.sum(-y * np.log(h_x) - (1 - y) * np.log(1 - h_x))\n",
    "        reg_l1 = self.alpha1 * np.sum(np.abs(theta))\n",
    "        reg_l2 = self.alpha2 * np.sum(np.square(theta))\n",
    "        \n",
    "        return cost + reg_l1 + reg_l2\n",
    "    \n",
    "    def h(self, x, theta):\n",
    "        return 1 / (1 + np.exp(-np.dot(x, theta)))\n",
    "    \n",
    "    def grad(self, x, y, theta):\n",
    "        m = x.shape[0]\n",
    "        h_x = self.h(x, theta)\n",
    "\n",
    "        gradient = -1 / m * np.dot(x.T, (y - h_x))\n",
    "        reg_l1 = self.alpha1 * np.sign(theta)\n",
    "        reg_l2 = 2 * self.alpha2 * theta\n",
    "\n",
    "        return gradient + reg_l1 + reg_l2\n",
    "    \n",
    "    def get_batch(self, x, y):\n",
    "        # TODO\n",
    "        return\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        x = self.preprocess(x)\n",
    "        \n",
    "        y = self.onehot(y)\n",
    "\n",
    "        (m, n), (_, c) = x.shape, y.shape\n",
    "        \n",
    "        self.mu, self.sigma = self.moments(x)\n",
    "        x = self.normalize(x)\n",
    "        \n",
    "        \n",
    "        theta = np.zeros(shape=(n, c))\n",
    "        v_1 = #TODO\n",
    "        v_t = v_1\n",
    "        for step in range(self.train_steps):\n",
    "            x_batch, y_batch = self.get_batch(x, y)\n",
    "            theta_grad = self.grad(x_batch, y_batch, theta)\n",
    "\n",
    "            # TODO Update v_t and theta\n",
    "            v_t = #TODO\n",
    "            theta = #TODO\n",
    "\n",
    "        self.theta = theta\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = self.preprocess(x)\n",
    "        x = self.normalize(x)\n",
    "        return self.h(x, self.theta).argmax(axis=1)\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        y_pred = self.predict(x)\n",
    "        return (y == y_pred).mean()\n",
    "\n",
    "reg = LogisticRegression(0, 0, 1e-3, 32, 1000).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_60452\\3537340466.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e-3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#print(f'Test accuracy: {reg.score(x_test, y_test) * 100}%')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_60452\\1516876638.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         '''\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py\u001b[0m in \u001b[0;36mdo_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2069\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_threads_suspended_single_notification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotify_thread_suspended\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthread_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_reason\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2070\u001b[1;33m                 \u001b[0mkeep_suspended\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_wait_suspend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuspend_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrom_this_thread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframes_tracker\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2071\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2072\u001b[0m         \u001b[0mframes_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py\u001b[0m in \u001b[0;36m_do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2105\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_internal_commands\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2106\u001b[1;33m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2108\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcancel_async_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_current_thread_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reg = LogisticRegression(0, 0, 1e-3, 32, 1000).fit(x_train, y_train)\n",
    "print(f'Test accuracy: {reg.score(x_test, y_test) * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отримана точність на тестовій вибірці має приблизно дорівнювати $88\\%\\ (!)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Виконайте оптимізацію параметрів $\\alpha_1,\\alpha_2$ за аналогією з лабораторною №2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Візуалізуйте матрицю помилок для кращої моделі:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-learn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "reg = LogisticRegression(0, 0, 1e-3, 32, 1000).fit(x_train, y_train)\n",
    "y_test_pred = reg.predict(x_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cm)\n",
    "plt.xlabel('Predicted class')\n",
    "plt.ylabel('True class')\n",
    "plt.xticks(range(10))\n",
    "plt.yticks(range(10))\n",
    "plt.show()\n",
    "\n",
    "print(f'Final accuracy {reg.score(x_test, y_test) * 100}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
