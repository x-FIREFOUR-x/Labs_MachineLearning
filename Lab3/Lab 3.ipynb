{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторна робота 3 - Логістична регресія."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У цій роботі Ви побудуєте логістичну регресію для класифікації зображень рукописних символів за датасетом MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У файлі **mnist.npz** міститься датасет MNIST. Завантажимо його та візуалізуємо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28)\n",
      "x_test shape: (10000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with np.load('mnist.npz') as npz:\n",
    "    x_train, y_train, x_test, y_test = [npz[k] for k in ['x_train', 'y_train', 'x_test', 'y_test']]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 4),  ncols=5)\n",
    "for a in ax:\n",
    "    i = np.random.randint(x_train.shape[0])\n",
    "    a.matshow(x_train[i], cmap='gray')\n",
    "    a.set_title(f'Label: {y_train[i]}')\n",
    "    a.axis('off')\n",
    "    \n",
    "print(f'x_train shape: {x_train.shape}')\n",
    "print(f'x_test shape: {x_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Як можна помітити, дані в датасеті MNIST подано у вигляді **тензора** рангу 3 (тензор рангу 1 це вектор, 2 - матриця), або, по-простому, у вигляді тривимірної таблиці. Ми поки що не знаємо алгоритмів, які здатні приймати на вхід такі дані, тому перетворимо весь наш датасет так, щоб кожна картинка була представлена у вигляді вектора довжини $28\\cdot28=784$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape after reshape: (60000, 784)\n",
      "x_test shape after reshape: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(-1, 28 * 28)\n",
    "x_test = x_test.reshape(-1, 28 * 28)\n",
    "\n",
    "print(f'x_train shape after reshape: {x_train.shape}')\n",
    "print(f'x_test shape after reshape: {x_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким чином ми отримали датасет, у якому 784 ознаки. Кожна ознака - інтенсивність певного пікселя картинки.\n",
    "\n",
    "Для більш ефективного зберігання, інтенсивності пікселів представлені цілочисельним типом uint8, який, на жаль, не підходить для виконання логістичної регресії (оскільки він цілочисельний). Перетворюємо дані в float32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реалізуйте методи з позначкою `#TODO` класу LogisticRegression:\n",
    "\n",
    "Метод `preprocess` повинен додавати колонку з одиниць у матрицю $X$. Опціонально - додайте поліноміальні або будь-які інші нелінійні ознаки.\n",
    "\n",
    "Метод `onehot` повинен виконувати onehot-перетворення:\n",
    "$$\n",
    " \\begin{array}{l}\n",
    "onehot:\\ \\mathbb{R}\\rightarrow \\mathbb{R}^{c}\\\\\n",
    "\\overline{onehot(y_{i} )}_{j} =\\begin{cases}\n",
    "1, & j=y_{i}\\\\\n",
    "0, & j\\neq y_{i}\n",
    "\\end{cases}\n",
    "\\end{array}\n",
    "$$\n",
    "де $c$ - кількість класів.\n",
    "\n",
    "Метод `h` - гіпотеза:\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "h( X) =\\sigma ( X\\theta )\\\\\n",
    "\\sigma ( x) =\\frac{1}{1+e^{-x}}\n",
    "\\end{array}\n",
    "$$\n",
    "Метод `J` повинен обчислювати оціночну функцію логістичної регресії:\n",
    "$$\n",
    "J( \\theta ) =\\frac{1}{m}\\sum ^{m}_{i=1}\\sum ^{c}_{j=1}( -y_{i,j} \\cdot \\log( h( x_{i})_j) \\ -\\ ( 1\\ -\\ y_{i,j}) \\cdot \\log( 1\\ -\\ h( x_{i})_j) +\\alpha _{1}\\sum ^{N}_{i=1}\\sum ^{c}_{j=1} |\\hat{\\theta }_{i,j} |+\\alpha _{2}\\sum ^{N}_{i=1}\\sum ^{c}_{j=1}\\hat{\\theta }^{2}_{i,j}\n",
    "$$\n",
    "Метод `grad` має обчислювати градієнт $\\frac{\\partial J}{\\partial \\theta }$:\n",
    "$$\n",
    "{\\displaystyle \\frac{\\partial J}{\\partial \\theta }} =-{\\displaystyle \\frac{1}{m}} X^{T} (Y-h(X) )+\\begin{bmatrix}\n",
    "0 &  &  & \\\\\n",
    " & 1 &  & \\\\\n",
    " &  & \\ddots  & \\\\\n",
    " &  &  & 1\n",
    "\\end{bmatrix} \\times ( \\alpha _{1} sign(\\theta )+2\\alpha _{2} \\theta )\n",
    "$$\n",
    "Метод `moments` має повертати вектор-рядки $\\mu,\\sigma$ для середнього і стандартного відхилення кожної колонки. Пам'ятайте, що колонку з одиницями не потрібно нормалізувати, тож відповідні середнє і стандартне відхилення для неї вкажіть рівними 0 і 1 відповідно. Можна використовувати функції \n",
    "[np.mean](https://numpy.org/doc/stable/reference/generated/numpy.mean.html) і [np.std](https://numpy.org/doc/stable/reference/generated/numpy.std.html).\n",
    "\n",
    "Метод `normalize` має виконувати нормалізацію $X$ на основі статистик $\\mu,\\sigma$, що повернув метод **moments**. Для того щоб уникнути ділення на 0, можете до $\\sigma$ додати маленьку величину, наприклад $10^{-8}$.\n",
    "\n",
    "Метод `get_batch` має повертати матриці $X_b, Y_b$ з довільно обраних $b$ елементів вибірки ($b$ у коді - `self.batch_size`).\n",
    "\n",
    "Метод `fit` виконує оптимізацію $J(\\theta)$. Для кращої збіжності реалізуйте алгоритм оптимізації **Momentum**:\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "v_t = \\gamma v_{t-1} + \\alpha\\nabla J(\\theta_{t-1})\\\\\n",
    "\\theta_t = \\theta_{t-1} - v_t\n",
    "\\end{array}\n",
    "$$\n",
    "де $\\gamma$ встановіть рівним $0.9$ (можете поекспериментувати з іншими величинами), $v_1=[0]_{N,c}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(\n",
    "        self,\n",
    "        alpha1,\n",
    "        alpha2,\n",
    "        learning_rate,\n",
    "        batch_size,\n",
    "        train_steps\n",
    "    ):\n",
    "        self.alpha1 = alpha1\n",
    "        self.alpha2 = alpha2\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.train_steps = train_steps\n",
    "    \n",
    "    def preprocess(self, x):\n",
    "        # TODO\n",
    "        return\n",
    "    \n",
    "    def onehot(self, y):\n",
    "        # TODO\n",
    "        return\n",
    "    \n",
    "    def normalize(self, x):\n",
    "        # TODO\n",
    "        return\n",
    "\n",
    "    def moments(self, x):\n",
    "        # TODO\n",
    "        return\n",
    "    \n",
    "    def J(self, x, y, theta):\n",
    "        # TODO\n",
    "        return\n",
    "    \n",
    "    def h(self, x, theta):\n",
    "        # TODO\n",
    "        return\n",
    "    \n",
    "    def grad(self, x, y, theta):\n",
    "        # TODO\n",
    "        return\n",
    "    \n",
    "    def get_batch(self, x, y):\n",
    "        # TODO\n",
    "        return\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        x = self.preprocess(x)\n",
    "        y = self.onehot(y)\n",
    "\n",
    "        (m, n), (_, c) = x.shape, y.shape\n",
    "        \n",
    "        self.mu, self.sigma = self.moments(x)\n",
    "        x = self.normalize(x)\n",
    "        \n",
    "        theta = np.zeros(shape=(n, c))\n",
    "        v_1 = #TODO\n",
    "        v_t = v_1\n",
    "        for step in range(self.train_steps):\n",
    "            x_batch, y_batch = self.get_batch(x, y)\n",
    "            theta_grad = self.grad(x_batch, y_batch, theta)\n",
    "\n",
    "            # TODO Update v_t and theta\n",
    "            v_t = #TODO\n",
    "            theta = #TODO\n",
    "\n",
    "        self.theta = theta\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = self.preprocess(x)\n",
    "        x = self.normalize(x)\n",
    "        return self.h(x, self.theta).argmax(axis=1)\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        y_pred = self.predict(x)\n",
    "        return (y == y_pred).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LogisticRegression(0, 0, 1e-3, 32, 1000).fit(x_train, y_train)\n",
    "print(f'Test accuracy: {reg.score(x_test, y_test) * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отримана точність на тестовій вибірці має приблизно дорівнювати $88\\%\\ (!)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Виконайте оптимізацію параметрів $\\alpha_1,\\alpha_2$ за аналогією з лабораторною №2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Візуалізуйте матрицю помилок для кращої моделі:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-learn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "reg = LogisticRegression(0, 0, 1e-3, 32, 1000).fit(x_train, y_train)\n",
    "y_test_pred = reg.predict(x_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cm)\n",
    "plt.xlabel('Predicted class')\n",
    "plt.ylabel('True class')\n",
    "plt.xticks(range(10))\n",
    "plt.yticks(range(10))\n",
    "plt.show()\n",
    "\n",
    "print(f'Final accuracy {reg.score(x_test, y_test) * 100}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
